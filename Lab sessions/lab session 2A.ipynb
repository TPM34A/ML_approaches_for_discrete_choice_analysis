{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discrete Choice Analysis: micro-econometrics and machine learning approaches\n",
    "\n",
    "## `Lab session 2A`<br> `Behavioural insights: Hybrid ANN-MNL models`\n",
    "\n",
    "**Delft University of Technology**<br>\n",
    "**July 2022**<br>\n",
    "**Instructor:** Sander van Cranenburgh <br>\n",
    "**TAs:**  Francisco Garrido Valenzuela & Lucas Spierenburg <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Instructions`\n",
    "\n",
    "**Lab sessions aim to:**<br>\n",
    "* Show and reinforce how models and ideas presented in class are put to practice.<br>\n",
    "* Help you gather hands-on machine learning skills.<br>\n",
    "\n",
    "**Lab sessions are:**<br>\n",
    "* Learning environments where you work with Jupyter notebooks and where you can get support from TAs and fellow students.<br> \n",
    "* Not graded and do not have to be submitted. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Workspace set-up`\n",
    "**Option 1: Google Colab**<br>\n",
    "Uncomment the following cell if you are running this notebook on Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!rm -rf /content/ML_approaches_for_discrete_choice_analysis\n",
    "#!git clone https://github.com/TPM34A/ML_approaches_for_discrete_choice_analysis\n",
    "#!pip install -r ML_approaches_for_discrete_choice_analysis/requirements_colab.txt\n",
    "#!cp -R \"/content/ML_approaches_for_discrete_choice_analysis/Lab sessions/data\" /content/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Option 2: Local environment**<br>\n",
    "Uncomment the following cell if you are running this notebook on your local environment, to install all dependencies on your Python version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -r requirements_local.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Application: Swiss mode choice` <br>\n",
    "In this lab session we will continue analysing mode choices behaviour. However, now our are aim is to obtain behavioural insights from ML models. <br>\n",
    "To do so, in this lab session you will (1) develop a hybrid ANN-MNL model, and use (2) SHAP values <br>\n",
    "\n",
    "**Learning objectives**. After completing the following exercises you will be able to: <br>\n",
    "1. **Estimate a  RUM-MNL model using PandasBiogeme<br>**\n",
    "2. **Train hybrid-ANN-MNL models and extract behavioural insights, such as VTTs, from them<br>**\n",
    "3. **Discuss the strength and weaknesses of using fully transparant RUM models, hybrid-models and fully opaque ANNs <br>**\n",
    "4. Use SHAP values to obtain behavioural insights from an otherwise opaque ML model (`lab session 2B`)<br>\n",
    "5. Use SHAP values to improve the model specification of a theory-driven RUM-MNL discrete choice model (`lab session 2B`)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Organisation`\n",
    "This lab session comprises **`6`** parts:\n",
    "1. Preparing your data set\n",
    "2. Estimating a RUM-MNL discrete choice model using PandasBiogeme (to benchmark)\n",
    "3. The hybrid ANN-MNL model\n",
    "4. Evaluating and comparing performances of trained models\n",
    "\n",
    "and comprises **`4`** exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required Python packages and modules\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from os import getcwd\n",
    "\n",
    "# Biogeme\n",
    "import biogeme.biogeme as bio\n",
    "import biogeme.database as db\n",
    "import biogeme.optimization as opt\n",
    "import biogeme.messaging as msg\n",
    "from biogeme import models\n",
    "from biogeme.expressions import Beta\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, classification_report\n",
    "\n",
    "# Tensorflow\n",
    "from tensorflow import keras\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Dense, Activation\n",
    "from keras.layers import Conv2D, Add, Reshape\n",
    "from keras.models import Model\n",
    "from keras.utils.np_utils import to_categorical   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Preparing your data set**\n",
    "To prepare the data set, we will:<br>\n",
    "    1.1 **Load** the data set<br>\n",
    "    1.2 **Clean** and **prepare** the data set<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.1 Load the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current working directory\n",
    "datafile_path = os.path.join(getcwd(),'data','')\n",
    "print(datafile_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load mode choice data into a pandas DataFrame\n",
    "df = pd.read_csv(datafile_path + 'swissmetro.dat',sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.2 Clean and prepare the data**<br>\n",
    "Since we work with the same data as in lab session 1, we take the same cleaning steps.<br>\n",
    "But, **in addition**, we set the cost for TRAIN and SM to zero for concession card holders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleaning\n",
    "\n",
    "# Only keep data for purposes 'Commute\" and \"Business\"\n",
    "df.drop(df[(df.PURPOSE != 1) & (df.PURPOSE != 3)].index, inplace=True) \n",
    "\n",
    "# Drop rows with unknown choices (CHOICE == 0)\n",
    "df.drop(df[df.CHOICE == 0].index, inplace=True) \n",
    "\n",
    "# In case of reamining missing values, replace them with 0\n",
    "df.fillna(0, inplace = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Correct cost for concession card holders**<br>\n",
    "When travellers have a concession card, the marginal cost for a trip is zero. That is, one extra trip does not cost anything extra. <br>\n",
    "Therefore, we 'manually' set the TRAIN and SM cost to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When GA equals 0, the traveller does not have a concession card; when GA equals 1, the traveller has a concession card. \n",
    "df['SM_CO'] = df.SM_CO * (df.GA == 0)             \n",
    "df['TRAIN_CO'] = df.TRAIN_CO * (df.GA == 0)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Estimating a RUM-MNL discrete choice model using PandasBiogeme (to benchmark)**\n",
    "To compare the performance and outputs of the hybrid ANN-MNL that we will build next, we first estimate our benchmark model: the canonical RUM-MNL.<br>\n",
    "\n",
    "\n",
    "In the RUM-MNL model utility is assumed to be linear additive-utility: \n",
    "\n",
    "$ V_{in} = ASC_{i} + \\sum_{m}\\beta_m x_{imn}$\n",
    "\n",
    "With this model we estimate the ASCs and the marginal utilities (i.e. betas) for: \n",
    "\n",
    "1. Travel Time (TT) [min] \n",
    "2. Travel Cost (CO) [Chf] (Swiss franc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert pandas df in biogeme database\n",
    "database = db.Database('swissmetro data', df)\n",
    "\n",
    "# The following statement allows you to use the names of the variable as Python variables.\n",
    "globals().update(database.variables)\n",
    "\n",
    "# Parameters to be estimated\n",
    "ASC_CAR = Beta('ASC_CAR', 0, None, None, 0)\n",
    "ASC_TRAIN = Beta('ASC_TRAIN', 0, None, None, 1)\n",
    "ASC_SM = Beta('ASC_SM', 0, None, None, 0)\n",
    "B_TIME = Beta('B_TIME', 0, None, None, 0)\n",
    "B_COST = Beta('B_COST', 0, None, None, 0)\n",
    "\n",
    "# Set cost to zero for concession card holders\n",
    "SM_COST = SM_CO * (GA == 0)             \n",
    "TRAIN_COST = TRAIN_CO * (GA == 0)       \n",
    "\n",
    "# Rescale attributes for numerical stability\n",
    "TRAIN_TT_SCALED   = TRAIN_TT / 100\n",
    "TRAIN_COST_SCALED = TRAIN_COST / 100\n",
    "SM_TT_SCALED      = SM_TT / 100\n",
    "SM_COST_SCALED    = SM_COST / 100\n",
    "CAR_TT_SCALED     = CAR_TT / 100\n",
    "CAR_COST_SCALED     = CAR_CO / 100\n",
    "\n",
    "# Utility functions\n",
    "V1 = ASC_TRAIN + B_TIME * TRAIN_TT_SCALED + B_COST * TRAIN_COST_SCALED\n",
    "V2 = ASC_SM    + B_TIME * SM_TT_SCALED    + B_COST * SM_COST_SCALED\n",
    "V3 = ASC_CAR   + B_TIME * CAR_TT_SCALED   + B_COST * CAR_COST_SCALED\n",
    "\n",
    "# Associate utility functions with the numbering of alternatives in df.CHOICE\n",
    "V = {1: V1, 2: V2, 3: V3}\n",
    "\n",
    "# Associate the availability conditions with the alternatives\n",
    "AV = {1: TRAIN_AV, 2: SM_AV, 3: CAR_AV}\n",
    "\n",
    "# Definition of the model. This is the contribution of each observation to the log likelihood function.\n",
    "logprob = models.loglogit(V, AV, CHOICE)\n",
    "\n",
    "# Create the Biogeme object\n",
    "biogeme = bio.BIOGEME(database, logprob)\n",
    "biogeme.modelName = 'RUM-MNL'\n",
    "biogeme.generatePickle = False\n",
    "biogeme.generateHtml = False\n",
    "\n",
    "# Calculate the null log likelihood for reporting.\n",
    "biogeme.calculateNullLoglikelihood(AV)\n",
    "\n",
    "# Estimate the parameters\n",
    "results = biogeme.estimate()\n",
    "\n",
    "# Report the results in a pandas table\n",
    "print('Estimated parameters')\n",
    "print('----------')\n",
    "print(results.getEstimatedParameters()[['Value','Std err','t-test','p-value']])\n",
    "\n",
    "# Perform a 'simulation' to compute the choice probabilities based on the estimated model (for later use)\n",
    "simulate = {\n",
    "    'Prob_TRAIN':      models.logit(V, AV, 1),\n",
    "    'Prob_SM':         models.logit(V, AV, 2),\n",
    "    'Prob_CAR':        models.logit(V, AV, 3)}\n",
    "\n",
    "# Create the biogeme simulation object\n",
    "biosim = bio.BIOGEME(database, simulate)\n",
    "prob_mnl = biosim.simulate(results.getBetaValues()).to_numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Show the model performance statistics and the  Value of Travel Time (VTT)**\n",
    "We can see the estimation results using the .shortSummary() function of Biogeme.<br>\n",
    "In addition, we compute the cross entropy and the Value-of-Travel-Time (VTT).<br>\n",
    "The cross entropy is computed as<br><br> \n",
    "$CE = -\\frac{1}{N} \\cdot LL(\\hat{\\beta})$, where *N* is the sample size<br><br>\n",
    "and, the VTT is computed using:<br><br>\n",
    "$VTT = -60\\cdot\\frac{\\beta_{TIME}}{\\beta_{COST}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the model performance\n",
    "print(results.shortSummary())\n",
    "\n",
    "# Compute and print the cross entropy\n",
    "cross_entropy =  -(results.getGeneralStatistics()['Final log likelihood'][0])/(results.getGeneralStatistics()['Sample size'][0])\n",
    "print(f'Cross entropy:\\t\\t\\t {cross_entropy:.3f}')\n",
    "\n",
    "# Compute the Value-of-Travel Time\n",
    "betas = results.getBetaValues()\n",
    "VTT_RUM   = 60*betas['B_TIME']/(betas['B_COST'])\n",
    "print(f'\\nThe estimated Value-of-Time using the RUM-MNL model is: {VTT_RUM:.2f} Chf/hr.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ``Exercise 1: The Value-of-Travel Time``\n",
    "`A` Interpret the estimation results of the MNL model in terms of the sing and sizes of the parameters<br>\n",
    "`B` The most recent Swiss value of travel time study finds a VTT of 27 ch/hr for car, and 14 chf/hr for Public Transport. <br>\n",
    "Could you think of reasons why the estimate found here is so much larger?<br>\n",
    "`C` Compute the Willingness to pay to go by SM instead of TRAIN, all esle being equal, using the formula: <br><br>\n",
    "$WtP_{SM} = - \\frac{ASC_{SM}-ASC_{TRAIN}}{\\beta_{COST}}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{green}{\\text{Add your answers here}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWERS\n",
    "# A)\n",
    "# B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. The hybrid ANN-MNL model**\n",
    "Next, we are going to build and train the hybrid ANN-MNL model. With this model we also aim to estimate the **Value-of-Time**.<br>\n",
    "To do so, we take the following steps:<br>\n",
    "3.1 Define lists of features for the MNL and ANN parts<br>\n",
    "3.2. Set the global variables and hyperparameters<br>\n",
    "3.3 Create the hybrid ANN-MNL object<br>\n",
    "3.4 Compile the model<br>\n",
    "3.5 Prepare the data for training the hybrid ANN-MNL model<br>\n",
    "3.6 Train the model<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3.1 Define lists of the features for the MNL and ANN parts**\n",
    "We place the features of behavioural interest: in casu, travel cost and travel time, in the *MNL part of the model*. <br>\n",
    "We place the remaining features in the *ANN part of the model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_mnl = ['TRAIN_TT','TRAIN_CO','SM_TT','SM_CO','CAR_TT','CAR_CO']\n",
    "features_ann = ['PURPOSE', 'FIRST','TICKET', 'WHO', 'LUGGAGE', 'AGE','MALE', 'GA','INCOME', 'ORIGIN','DEST','TRAIN_HE','SM_HE','SM_SEATS','TRAIN_AV','SM_AV','CAR_AV']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3.2 Set the global variables and hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables (do not change)\n",
    "OBS = int(len(df))                      # Number of observations\n",
    "NALT = int(3)                           # Number of alternatives in the data set.\n",
    "no_X_MNL = int(len(features_mnl)/NALT)  # Number of attributes with behavioural interest (-->MNL model part).  In this example we are particularly interested in the VTT--> Cost & Tume\n",
    "no_X_ANN = int(len(features_ann))       # Number of features without behavioural interest (-->ANN model part). \n",
    "\n",
    "# Hyperparameters\n",
    "num_nodes = 10                          # Number of nodes in hidden layer(s). Again we use 2 hidden layers with *num_nodes* nodes each\n",
    "alpha = 0.00001                         # L2 regularisation\n",
    "nEpoch = 50                             # Max number epochs for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3.3 Create the hybrid ANN-MNL object**\n",
    "We build the hybrid ANN-MNL models in a number of steps. That is, we create the layers separately and connect them to one another.<br>\n",
    "Specifically, next we create:<br>\n",
    "- MNL part\n",
    "- ANN part\n",
    "- A layer where the utilities of the MNL and ANN parts come together\n",
    "- Output layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MNL part**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create the MNL part, we use a convolution layer. Using a convolution layer is merely a *trick* to ensure the same weights are used for the cost and time across the three mode alternatives. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the input layer for MNL part\n",
    "X_MNL = Input((no_X_MNL, NALT,1), name = 'Features2MNL')\n",
    "\n",
    "# Create the utility layer for the MNL part.\n",
    "# kernel_size = [no_X_MNL,1] defines the height and width of the convolution kernel\n",
    "# strides = (2,1) governs the movement of the kernel over the input\n",
    "# padding = 'valid' means that NO padding is used (not discussed in class)\n",
    "V_MNL = Conv2D(filters = 1, kernel_size = [no_X_MNL,1], strides = (2,1), padding = 'valid', name = 'MNL_layer', use_bias = False, trainable = True)(X_MNL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANN part**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create the ANN part, we use a dense layer. In tensorflow **Dense** refers to a fully connected MLP layer.<br>\n",
    "In the case we create two dense layers, each with *num_nodes* nodes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the input layer for the ANN part\n",
    "X_ANN = Input((no_X_ANN), name ='Features2ANN')\n",
    "\n",
    "# Create the hidden layers for the ANN part\n",
    "reg = keras.regularizers.L2(alpha)  # defines regularisation settings. Here we use L2 regularisation. \n",
    "layer1_ANN = Dense(units = num_nodes, name = \"ANN_HiddenLayer1\", use_bias = True, kernel_regularizer = reg)(X_ANN)      \n",
    "layer2_ANN = Dense(units = num_nodes, name = \"ANN_HiddenLayer2\", use_bias = True, kernel_regularizer = reg)(layer1_ANN)\n",
    "\n",
    "# Create the  \n",
    "V_ANN = Dense(units = NALT, name = \"V_ANN\", use_bias = True)(layer2_ANN) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since X_ANN contains 17 features, we created two dense hidden layers, and we compute the utility for 3 alternatives, <br>\n",
    "the created ANN part of the model looks like this:\n",
    "<p align=\"center\\\">\n",
    "<img width=\"600\" src=\"https://github.com/FGarridoV/resources/blob/main/NN.png?raw=true\">\n",
    "</p> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part where the MNL and ANN parts come together**<br>\n",
    "The output of the MNL part of the model is V_MNL; the output of the ANN part of the model is V_ANN.<br>\n",
    "Next, we must create a layer that simply takes the sum:<br><br>\n",
    "$V_{TRAIN}=V_{MNL,TRAIN}+V_{ANN,TRAIN}$<br>\n",
    "$V_{SM}=V_{MNL,SM}+V_{ANN,SM}$<br>\n",
    "$V_{CAR}=V_{MNL,CAR}+V_{ANN,CAR}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the tensors to [1 X NALT]\n",
    "V_MNL = Reshape([NALT], name = 'Flatten_MNL')(V_MNL)\n",
    "V_ANN = Reshape([NALT], name = 'Flatten_ANN')(V_ANN) \n",
    "\n",
    "# Create a layer that simply sums the utilities of the MNL and ANN parts\n",
    "V_MNL_ANN = Add(name = \"sum_V_MNL_V_ANN\")([V_MNL,V_ANN])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output layer**<br>\n",
    "We are almost done. We have the $V_{TRAIN}$, $V_{SM}$, and $V_{CAR}$. The only thing that we now need is a softmax (a.k.a. logit) layer that maps V onto Probability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a logit output layer with V_MNL_ANN as input\n",
    "logitProb = Activation('softmax', name = 'Probability')(V_MNL_ANN)\n",
    "\n",
    "# Create the model, by putting everything together\n",
    "model = Model(inputs = [X_MNL, X_ANN], outputs = logitProb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the model is built, we inspect the model object, using model.summary(). For example, we look at whether the layers have the expected shapes and number of weights (Param #)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The structure of the model (conceptually) is shown below.\n",
    "<p align=\"center\\\">\n",
    "<img width=\"600\" src=\"https://github.com/FGarridoV/resources/blob/main/hybrid_model.png?raw=true\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3.4 Compile the model**\n",
    "When we are satisfied with the created model structure, we compile the model. When we say we 'compile the model', we mean the model and the optimiser and wrapped together into a trainable object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that we use the Adam optimiser, with the shown settings\n",
    "opt = keras.optimizers.Adam(learning_rate=0.001,beta_1=0.9,beta_2=0.999,epsilon=1e-07)\n",
    "model.compile(loss='categorical_crossentropy', metrics = [\"accuracy\"], optimizer = opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3.5 Prepare the data for training the hybrid ANN-MNL model**\n",
    "Preparing the model for training this model involves to:<br>\n",
    "* Scale the features. This must be done separately for the MNL and ANN parts.\n",
    "* Create the train and test data sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scale the features**<br>\n",
    "Before training an ANN, we must scale the input features. However, since we want to compute VTTs the features of the MNL part cannot just be scaled by just any scaler. This would hamper the intepretation of the associated betas. Therefore, we must manually scale the features for the MNL part, while we can use the `sk-learn's` StandardScaler for the features for the ANN part. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scale the features for MNL part**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe with features for MNL part\n",
    "x_mnl = df[features_mnl]\n",
    "\n",
    "# Manually scale all features by 100 (same scaling as in biogeme model)\n",
    "scale = 100\n",
    "x_mnl = np.divide(x_mnl,scale)\n",
    "\n",
    "# Convert into a numpy array and reshape so the convolution layer can handle it.\n",
    "# As convolution layers are designed for images, they take 4D tensors as inputs: Batch x Width x Height x RGB color channels\n",
    "# In this case we use only 1 color channel (as if the image is in greyscale)\n",
    "x_mnl = np.expand_dims(np.swapaxes(np.array(x_mnl.T).reshape((NALT,no_X_MNL,OBS)),axis1=2,axis2=0),3)\n",
    "print('Shape of x_mnl', x_mnl.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scale the features for ANN part**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe with features for ANN part\n",
    "x_ann = df[features_ann]\n",
    "\n",
    "# Define the list of features that need to be scaled (excluding availabilities and the choice!)\n",
    "features2scale = ['PURPOSE', 'FIRST','TICKET', 'WHO', 'LUGGAGE', 'AGE','MALE', 'INCOME', 'GA', 'ORIGIN','DEST','TRAIN_HE','SM_HE','SM_SEATS']\n",
    "\n",
    "# Initiate scaler object & fit to features\n",
    "scaler = StandardScaler()  \n",
    "scaler.fit(x_ann.loc[:,features2scale])  \n",
    "\n",
    "# Create new dataframe containing both the scaled features AND the (unscaled) ones. In particular, we do not want to scale the availabilities\n",
    "x_ann = df[features_ann].copy()\n",
    "x_ann.at[:, features2scale] = scaler.transform(df.loc[:,features2scale])\n",
    "x_ann = np.array(x_ann)\n",
    "print('Shape of x_ann',x_ann.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create the train and test data sets**<br>\n",
    "We use sk-learn's train_test_split function to obtain a train and test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe with the output target\n",
    "Y = df['CHOICE']\n",
    "\n",
    "# Unlike sk-learn, Tensorflow requires the targets to be dummmy coded\n",
    "Y_cat = to_categorical(Y-1, num_classes = NALT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into a training and test part\n",
    "# We split both the features for the MNL and ANN part\n",
    "# We use the same random state. Thereby we make sure that the train and test for the MNL and ANN part contain the same observations\n",
    "X_mnl_train, X_mnl_test, Y_train, Y_test = train_test_split(x_mnl, Y_cat, random_state = 1, test_size = 0.35)\n",
    "X_ann_train, X_ann_test, Y_train, Y_test = train_test_split(x_ann, Y_cat, random_state = 1, test_size = 0.35)\n",
    "print('Total number of observations in the data set = ', len(x_mnl))\n",
    "print('Number of observations in the training set   = ', len(X_mnl_train))\n",
    "print('Number of observations in the test set       = ', len(X_mnl_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3.6 Train the model**\n",
    "Finally, we are ready to train the model! Let's see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit([X_mnl_train, X_ann_train],Y_train, epochs = nEpoch, verbose = 1, validation_data = ([X_mnl_test, X_ann_test], Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's have a look at the training progress, in terms of loss and accuracy\n",
    "# plot loss as a function of epochs\n",
    "fig, axes =plt.subplots(1, 1, figsize=(16, 6))\n",
    "plt.subplot(121)\n",
    "plt.title('Cross Entropy Loss')\n",
    "plt.plot(history.history['loss'],     color = 'blue', label = 'train')\n",
    "plt.plot(history.history['val_loss'], color = 'red', label = 'test')\n",
    "plt.ylim(0.6,1)\n",
    "plt.legend()\n",
    "\n",
    "# plot accuracy\n",
    "plt.subplot(122)\n",
    "plt.title('Classification Accuracy')\n",
    "plt.plot(history.history['accuracy'],     color = 'blue', label = 'train')\n",
    "plt.plot(history.history['val_accuracy'], color = 'red', label = 'test')\n",
    "plt.ylim(0, 1)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Exercise 2: Training the hybrid ANN-MNL model`\n",
    "`A` Training time of the hybrid ANN-MNL model using tensorflow is considerably slower than of the MLP (trained in sk-learn). Can you think of reasons why?<br>\n",
    "`B` Performing a full-fletch hypertuning would be recommended, but is too time-comsuming for this lab session. Manually test the sensitivity to L2 regularisation (which turned out to be particularly important for the MLP). To do so, re-run this notebook with alpha is {1,0.1,0.00001}. Report you results. What L2 works best?<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{blue}{\\text{After you are finished testing, set the L2 to the best value found.}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{green}{\\text{Add your answers here}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWERS\n",
    "# A)\n",
    "# B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4. Evaluating and comparing performances across trained models**<br>\n",
    "4.1 Evaluating and compairng model performance based on cross entropy & rho_square<br>\n",
    "4.2 Evaluating and comparing model outcomes: the VTT<br>\n",
    "4.3 Evaluating and comparing model performance based on confusion metrics<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4.1 Evaluating and comparing model performance based on cross entropy & rho_square**\n",
    "Machine learning researchers usually evaluate the performance of a classification model using the cross-entropy, while choice modellers usually look at the Log-likelihood (LL) and the rho_square. As there is no standard function that outputs the evaluation metrics of both disciplines, below we (again) create our **own evaluation function**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create an evaluation function that returns key evaluation metrics: LL, LL0, cross_entropy, rho_sq\n",
    "# To compute these performance metrics, the function takes as inputs:\n",
    "#   - the predicted probabilities (prob) [N x NALT]\n",
    "#   - the choices (Y) [N x NALT] Hence dummy coded: [0 0 1; 0 1 0; 1 0 0]\n",
    "#   - the availabilities (AV) [N x NALT]\n",
    "def eval_performance(prob,Y,AV):\n",
    "    \n",
    "    # Calculate the likelihood of the data given the model\n",
    "    LL = np.sum(np.log(np.sum(prob*Y,axis=1)))\n",
    "\n",
    "    # Calculate the Null-loglikelihood\n",
    "    LL0 = np.sum(np.log(np.divide(1,np.sum(AV,axis=1))))\n",
    "\n",
    "    # Calculate cross-entropy\n",
    "    cross_entropy =  -LL/len(AV)\n",
    "    \n",
    "    # Calculate the rho_sq\n",
    "    rho_sq = 1 -(LL/LL0)\n",
    "\n",
    "    return LL, LL0, cross_entropy, rho_sq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate the performance of the hybrid model**<br>\n",
    "To do so, we use our own eval_performance function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate performance on the training and test data sets of the hybird ANN-MNL model\n",
    "eval_train = eval_performance(model.predict([X_mnl_train, X_ann_train]),Y_train, X_ann_train[:,[-3,-2,-1]])\n",
    "eval_test  = eval_performance(model.predict([X_mnl_test , X_ann_test ]),Y_test , X_ann_test[:,[-3,-2,-1]])\n",
    "\n",
    "# Print the results\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "results = pd.DataFrame({'data set':     ['Train','Test'],\n",
    "                        'LL':           [eval_train[0], eval_test[0]],\n",
    "                        'LL0':          [eval_train[1], eval_test[1]],\n",
    "                        'cross_entropy':[eval_train[2], eval_test[2]],\n",
    "                        'rho_sq':       [eval_train[3], eval_test[3]]})\n",
    "\n",
    "print('Model performance of the hybrid ANN-MNL model')\n",
    "print(results.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate the performance of the RUM-MNL model**<br>\n",
    "To do so, we again use our own eval_performance function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For comparison, we also evaluate performance on the training and test data sets of the linear-additive RUM model\n",
    "eval_mnl = eval_performance(prob_mnl,np.transpose([Y ==1,Y ==2,Y ==3]), df[['TRAIN_AV','SM_AV','CAR_AV']])\n",
    "\n",
    "# Print the results\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "results = pd.DataFrame({'data set':     ['All data'],\n",
    "                        'LL':           [eval_mnl[0]],\n",
    "                        'LL0':          [eval_mnl[1]],\n",
    "                        'cross_entropy':[eval_mnl[2]],\n",
    "                        'rho_sq':       [eval_mnl[3]]})\n",
    "\n",
    "print('Model performance of the RUM-MNL model')\n",
    "print(results.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4.2 Evaluating and comparing model outcomes: the VTT**\n",
    "The objective in this lab session is to compute the VTT using the hybrid ANN-MNL model. <br>\n",
    "Assessing model outcomes, such as the VTT, is also part of model evaluation. After all, a model that fits well, but throws an unrealistic VTT is not useful.<br>\n",
    "To compute the VTT we access the learned weights of the hybrid ANN-MNL model. Since the MNL part is linear and additive, we can compute the VTT in the same way as for the MNL model:<br><br>\n",
    "$VTT = -60\\cdot\\frac{\\beta_{TIME}}{\\beta_{COST}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the weights of the MNL_layer\n",
    "betas_layer = model.get_layer(name = 'MNL_layer')\n",
    "betas = betas_layer.get_weights()\n",
    "beta_TIME = np.squeeze((betas[0][0]))\n",
    "beta_COST = np.squeeze((betas[0][1]))\n",
    "print(f'Beta_TIME = \\t{beta_TIME:.3f}') \n",
    "print(f'Beta_COST = \\t{beta_COST:.3f})')\n",
    "\n",
    "# Compute VTT using the hybrid ANN-MNL model\n",
    "VTT_hybrid = 60*(beta_TIME/beta_COST)\n",
    "print(f'\\nThe estimated Value-of-Time using the hybrid ANN-MNL model is: {VTT_hybrid:.2f} Chf/hr.')\n",
    "\n",
    "# Compare with the the estimated VTT from the RUM-MNL model\n",
    "print(f'\\nThe estimated Value-of-Time using the RUM-MNL model is:        {VTT_RUM:.2f} Chf/hr.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4.3 Evaluating and comparing model performance based on confusion metrics**\n",
    "Next, we compare the predictions made between the MNL and hybrid ANN-MNL model<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the choices (hits) using the MNL and hybrid-ANN-MNL models on the full data set\n",
    "Y_pred_mnl = np.argmax(prob_mnl, axis =1)+1 # <-- Argument for finding the column with the highest predicted probability for the MNL model\n",
    "Y_pred_hybrid = np.expand_dims(np.argmax(model.predict([x_mnl, x_ann]),axis = 1),axis =1)+1\n",
    "\n",
    "# Show the confusion matrices to asses difference between the predictions of the MNL and hybrid ANN-MNL models\n",
    "ylabels = ['TRAIN','SM','CAR']\n",
    "fig, ax = plt.subplots(2,2,figsize = (14,10))\n",
    "fig.set_tight_layout(True)\n",
    "\n",
    "# Display confusion matrices, non-normalised and normalised\n",
    "cm1 = ConfusionMatrixDisplay.from_predictions(y_true=Y,y_pred=Y_pred_mnl,    display_labels = ylabels, normalize=None,  ax=ax[(0,0)])\n",
    "cm2 = ConfusionMatrixDisplay.from_predictions(y_true=Y,y_pred=Y_pred_mnl,    display_labels = ylabels, normalize='true',ax=ax[(1,0)])\n",
    "cm3 = ConfusionMatrixDisplay.from_predictions(y_true=Y,y_pred=Y_pred_hybrid, display_labels = ylabels, normalize=None,  ax=ax[(0,1)])\n",
    "cm4 = ConfusionMatrixDisplay.from_predictions(y_true=Y,y_pred=Y_pred_hybrid, display_labels = ylabels, normalize='true',ax=ax[(1,1)])\n",
    "\n",
    "# Add titles to confusion matrices\n",
    "cm1.ax_.set_title('RUM_MNL predictions')\n",
    "cm2.ax_.set_title('RUM_MNL predictions - normalised')\n",
    "cm3.ax_.set_title('Hybrid ANN-MNL')\n",
    "cm4.ax_.set_title('Hybrid ANN-MNL - normalised')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Exercise 3: Model performance evaluation and comparison`<br>\n",
    "`A` Interpret and explain the difference in the cross entropy performance of the RUM-MNL, Hybrid ANN-MNL, and ANN (previous lab session)<br>\n",
    "`B` Interpret and explain the difference between the confusion matrices of the MNL and hybrid ANN-MNL models<br>\n",
    "`C` Show the Precision, Recall, and F1 score for the hybrid ANN-MNL and for the RUM-MNL, using `sk-learn's` `classification_report` function and interpret the results<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{green}{\\text{Add your answers here}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWERS\n",
    "# A Cross entropy performance is best for the fully flexible ANN (lab session 1), then comes the hybrid model, and then the RUM-MNL.\n",
    "# CE ANN        0.65\n",
    "# CE hybrid     0.70\n",
    "# CE MNL        0.79\n",
    "# This is in line with the expectations\n",
    "# B the improved performance of the hybrid ANN-MNL is also reflected in the improved confusion matrix. That is, the hybrid model is better at predicting TRAIN and SM classes\n",
    "# C We see that in particular the Recall of TRAIN is improved using the hybrid ANN-MNL specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To calculate the precision, recal and f1 score we conveniently use sk-learn's 'classification_report' functionality\n",
    "print('Classification report forthe RUM-MNL model\\n',\n",
    "    classification_report(Y,Y_pred_mnl, target_names= ylabels))\n",
    "print('\\nClassification report for hybrid ANN-MNL model\\n',\n",
    "    classification_report(Y,Y_pred_hybrid, target_names= ylabels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Exercise 4: Hand-engineering for interactions with cost needed?`\n",
    "In part 1 ('Preparing your data') we set the cost for TRAIN and SM to zero for concession card holders (GA == 1). <br>\n",
    "`A` Re-run your whole notebook, but without setting the cost for TRAIN and SM to zero. <br>\n",
    "Look at the model performance (e.g. cross entropy) as well as the VTT. What catches the eye?<br>\n",
    "`B` Could you think of a reason that explains the difference between the run with and without having set the cost to zero for TRAIN and SM?<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{green}{\\text{Add your answers here}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWERS\n",
    "# A)\n",
    "# B)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "570feb405e2e27c949193ac68f46852414290d515b0ba6e5d90d076ed2284471"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
